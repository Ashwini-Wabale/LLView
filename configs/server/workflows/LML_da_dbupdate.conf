# Copyright (c) 2023 Forschungszentrum Juelich GmbH.
# This file is part of LLview. 
#
# This is an open source software distributed under the GPLv3 license. More information see the LICENSE file at the top level.
#
# Contributions must follow the Contributor License Agreement. More information see the CONTRIBUTING.md file at the top level.
#
# Contributors:
#    Wolfgang Frings (Forschungszentrum Juelich GmbH) 
#    Filipe Guimar√£es (Forschungszentrum Juelich GmbH) 

<LML_da_workflow>
  <vardefs>
    <var key="instdir"        value="${LLVIEW_HOME}/da" /> 
    <var key="configdir"      value="${LLVIEW_CONF}"/>
    <!-- Common folders -->
    <var key="tmpdir"         value="./tmp"/>
    <var key="permdir"        value="./perm"/>
    <var key="logdir"         value="./logs"/>
    <var key="archdir"        value="./arch"/>
    <var key="shareddir"      value="${LLVIEW_SHARED}/remote" />
    <!-- These variables are used by LML_da.pl -->
    <var key="signalfilename" value="RUNNING_db"/>
    <!-- These variables are used by LML_da_par_step.pl -->
    <var key="steptimingfile" value="./tmp/step_timing_dbupdate_new.xml" />
    <var key="name"           value="DBupdate" />
    <var key="stepcounter"    value="./perm/stepcounter.dat" />
    <!-- Variables used below -->
    <var key="perl"           value="perl" />
    <var key="python"         value="${PYTHON}" />
  </vardefs>

  <step active="1" id="start" exec_after="" type="execute">
    <cmd exec="echo 'starting LML_da_dbupdate.conf'"/>
    <cmd exec="$perl $instdir/utils/increase_counter.pl $stepcounter"/>
    <!-- Adding trigger XML file to be used by databases that may not be always updated -->
    <cmd exec="$python $instdir/utils/trigger.py --xml $tmpdir/trigger.xml"/> 
  </step>

  <!-- --------------------------------------- -->
  <!--   copy data produced by remote system   -->
  <!-- --------------------------------------- -->

  <step active="1" id="cpdata" exec_after="start" type="execute">
    <cmd  exec="cp -p $shareddir/sysinfo_LML.xml       $tmpdir;
                cp -p $shareddir/nodes_LML.xml         $tmpdir; 
                cp -p $shareddir/jobs_LML.xml          $tmpdir;
                cp -p $shareddir/reservation_LML.xml   $tmpdir;
                cp -p $shareddir/classes_LML.xml       $tmpdir; 
                cp -p $shareddir/jobs_step_LML.xml     $tmpdir;
                cp -p $shareddir/slurmaccounts_LML.xml $tmpdir;" />
  </step>

  <!-- --------------------------------------- -->
  <!--   archive old data from database        -->
  <!-- --------------------------------------- -->

  <step active="1" id="LMLDBarch" exec_after="start" type="execute">
  <cmd  exec="$perl $instdir/LML_DBupdate/LML_DBarch.pl --dbdir=$permdir/db/
                                                        --archdir=$archdir/db/
                                                        --dblist=jobstate,jobstep,loadmemstate,fsusagestate_all,fsusagestate_project,fsusagestate_scratch,fsusagestate_fastdata,fsusagestate_home,icmapstate,fabricstate,gpustate,sysstatstate,nodeerr,steptimings,DBstat,transfer,pcpucoresstate
                                                        --config $configdir/server/LLgenDB/LLgenDB.yaml
                                                        --maxprocesses 10
                                                        "/>
  </step>

  <!-- ---------------------------------------------------- -->
  <!--   collect data from daemons and other local sources  -->
  <!-- ---------------------------------------------------- -->

  <!--   STEP: plugin for I/O info from GPFS daemon   -->
  <step active="0" id="da_io_gpfs" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/GPFS/da_io_client_info_LML.pl 
                -lml -asc -hist -histdb=$permdir -stat  
                --prefixfile=$instdir/workflows/system/server/prefixes_mmpmon_stage2_local.txt 
                -maxwindow=9000 --nodepostfix='(i|og.jureca)$' -v  
                -tsfile $permdir/io_ts_stat.dat 
                $tmpdir/io_out_l"/>
  </step>

  <!--   STEP: plugin for information from Prometheus  (Cores, Infiniband and GPU)   -->
  <step active="0" id="da_prometheus" exec_after="start" type="execute">
    <cmd exec="/usr/bin/python3.9 $instdir/rms/Prometheus/prometheus.py --config $configdir/plugins/promet.yml
                                                                                      --outfolder $tmpdir
                                                                                      "/>
  </step>

  <!--   STEP: copying job error information generated by Healthchecker action   -->
  <step active="0" id="da_errmsg" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/jobs_errmsg_HC_LML_new.xml   
                      $tmpdir/jobs_errmsg_HC_LML.xml   
                      $tmpdir/jobs_errmsg_HC_LML_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/jobs_errmsg_HC_LML_new.xml $tmpdir/jobs_errmsg_HC_LML_done.xml"/>
  </step>

  <!--   STEP: copying node error information generated by Healthchecker action   -->
  <step active="0" id="da_nodeerrmsg" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/nodes_errmsg_HC_LML_new.xml   
                      $tmpdir/nodes_errmsg_HC_LML.xml   
                      $tmpdir/nodes_errmsg_HC_LML_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/nodes_errmsg_HC_LML_new.xml $tmpdir/nodes_errmsg_HC_LML_done.xml"/>
  </step>

  <!--   STEP: plugin to get info from gitlab repos  -->
  <!-- To activate the CB, this step must be configured and activated  -->
  <!-- (in particular, the config file(s) in configs/plugins/cb/), -->
  <!-- and the following configurations must be uncommented in the YAML files: -->
  <!-- File: configs/server/LLgenDB/LLgenDB.yaml: -->
  <!--   %include "conf_cb/CB.yaml" -->
  <!-- File: configs/server/LLgenDB/conf_jobreport/jobreport_footer.yaml: -->
  <!--   %include "../conf_cb/footer_cb.yaml" -->
  <!-- File: configs/server/LLgenDB/conf_jobreport/jobreport_vars.yaml: -->
  <!--   %include "../conf_cb/vars_cb.yaml" -->
  <!-- File: configs/server/LLgenDB/conf_jobreport/data_json/jobreport_datafiles_json_support.yaml: -->
  <!--   %include "../../conf_cb/tablecsv_cb.yaml" -->
  <!--   %include "../../conf_cb/csv_cb.yaml" -->
  <!-- File: configs/server/LLgenDB/conf_jobreport/data_templates/jobreport_datafiles_table_templates.yaml: -->
  <!--   %include "../../conf_cb/template_cb.yaml" -->
  <!-- File: configs/server/LLgenDB/conf_jobreport/views/jobreport_view_support.yaml: -->
  <!--     %include "../../conf_cb/tab_cb.yaml" -->
  <step active="0" id="da_gitlab" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/exec_every_n_step_or_empty.pl $permdir/stepcount_gitlab.dat 
                                                                    15
                                                                    $instdir/utils/empty_LML.xml 
                                                                    $tmpdir/CB.xml
                                                                    $python $instdir/rms/gitlab/gitlab.py
                                                                                                          --config $configdir/plugins/cb/ 
                                                                                                          --tsfile $permdir/gitlab_last_timestamp.dat
                                                                                                          --singleLML $tmpdir/CB.xml
                                                                                                          --repofolder $tmpdir/repos
                                                                                                          --outconfigfolder $configdir/server/LLgenDB/conf_cb/
                                                                                          "/>
  </step>

  <!--   STEP: copying interconnect mapping 'icnodemap_new.xml' generated by icmap action   -->
  <step active="1" id="da_icmap" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/icnodemap_new.xml   
                      $tmpdir/icnodemap.xml
                      $tmpdir/icnodemap_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/icnodemap_new.xml $tmpdir/icnodemap_done.xml"/>
  </step>

  <!--   STEP: plugin for system information from checkMK   -->
  <step active="0" id="da_checkmk" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/CheckMK/cmk_query_env.pl -v 
                      -system JRC -output $tmpdir/checkmk.xml"/>
  </step>

  <!--   STEP: plugin for power info from Prometheus   -->
  <step active="0" id="da_rackpwr" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/PROMETHEUS/da_query_systat.pl -v 
                      -metric power -system JRC
                      -lml -ascii 
                      $tmpdir/rackpwr"/>
  </step>

  <!--   STEP: generating user/project/mentor/support mapping information (every 15 steps)   -->
  <step active="1" id="webservice" exec_after="start" type="execute">
    <cmd  exec="mkdir -p $permdir/wservice" />
    <cmd  exec="$perl $instdir/utils/exec_every_n_step_or_empty.pl $permdir/stepcount_webservice.dat 
                                                                    15
                                                                    $instdir/utils/empty_LML.xml 
                                                                    $permdir/wservice/accountmap.xml
                                                                    /usr/bin/perl $instdir/rms/JSCinternal/get_webservice_accounts.pl 
                                                                                          -system jureca 
                                                                                          --support $permdir/wservice/support_input.dat 
                                                                                          -lml $permdir/wservice/accountmap.xml
                                                                                          "/>
  </step>

  <!--   STEP: copying timing information of dbupdate action (this one)   -->
  <step active="1" id="da_step_timings_DB" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_dbupdate_new.xml   
                                                $tmpdir/step_timing_dbupdate_LML.xml   
                                                $tmpdir/step_timing_dbupdate_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_dbupdate_new.xml $tmpdir/step_timing_dbupdate_LML_done.xml"/>
  </step>

  <!--   STEP: copying timing information of liveview action   -->
  <step active="0" id="da_step_timings_LV" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_liveview_new.xml   
                                                $tmpdir/step_timing_liveview_LML.xml   
                                                $tmpdir/step_timing_liveview_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_liveview_new.xml $tmpdir/step_timing_liveview_LML_done.xml"/>
  </step>

  <!--   STEP: copying timing information of jobreport action   -->
  <step active="1" id="da_step_timings_JR" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_jobreport_new.xml   
                                                $tmpdir/step_timing_jobreport_LML.xml   
                                                $tmpdir/step_timing_jobreport_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_jobreport_new.xml $tmpdir/step_timing_jobreport_LML_done.xml"/>
  </step>

  <!-- STEPS: Copying internal statistics files -->
  <step active="1" id="da_stat" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/LMLDBupdate_stat_LML_new.xml   
                                                $tmpdir/LMLDBupdate_stat_LML.xml   
                                                $tmpdir/LMLDBupdate_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/LMLDBupdate_stat_LML_new.xml $tmpdir/LMLDBupdate_stat_LML_done.xml"/>
  </step>
  <step active="1" id="da_jr_stat" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/LL_jobreport_stat_LML_new.xml   
                                                $tmpdir/LL_jobreport_stat_LML.xml   
                                                $tmpdir/LL_jobreport_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/LL_jobreport_stat_LML_new.xml $tmpdir/LL_jobreport_stat_LML_done.xml"/>
  </step>
  <step active="1" id="da_tr_stat" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/transferreports_stat_LML_new.xml   
                                                $tmpdir/transferreports_stat_LML.xml   
                                                $tmpdir/transferreports_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/transferreports_stat_LML_new.xml $tmpdir/transferreports_stat_LML_done.xml"/>
  </step>


  <!--   STEP: collection step to signal that all the data-gathering steps are completed   -->
  <step active="1" id="rawdataready" exec_after="cpdata,LMLDBarch,da_io_gpfs,da_prometheus,da_gitlab,da_icmap,da_errmsg,da_nodeerrmsg,da_checkmk,webservice,da_rackpwr,da_step_timings_DB,da_step_timings_P3,da_step_timings_JR,da_stat,da_jr_stat,da_tr_stat" type="execute">
    <cmd  exec="echo 'raw data ready'"/>
  </step>


  <!-- --------------------------------------- -->
  <!--   add data to database                  -->
  <!-- --------------------------------------- -->
  <!-- Depending on the plugins used above, more files should be added 
  <!-- to the steps 'LMLDBupdate' and 'combineLML_all' below, for example: -->
  <!--                                      $tmpdir/gpus_LML.xml           -->
  <!--                                      $tmpdir/ibms_LML.xml           -->
  <!--                                      $tmpdir/cores_LML.xml          -->
  <!--                                      $tmpdir/cores.percore_LML.xml  -->
  <!--                                      $tmpdir/CB.xml                 -->
  <!-- STEP: This step should include all xml files to be included in the database -->
  <step active="1" id="LMLDBupdate" exec_after="rawdataready" type="execute">
    <cmd  exec="$perl $instdir/LML_DBupdate/LML_DBupdate.pl --dbdir=$permdir/db/ 
                                                            --config $configdir/server/LLgenDB/LLgenDB.yaml 
                                                            --maxprocesses 6
                                                            $tmpdir/sysinfo_LML.xml 
                                                            $tmpdir/nodes_LML.xml 
                                                            $tmpdir/jobs_LML.xml
                                                            $tmpdir/reservation_LML.xml 
                                                            $tmpdir/classes_LML.xml 
                                                            $tmpdir/jobs_step_LML.xml
                                                            $tmpdir/LMLDBstat.xml 
                                                            $permdir/wservice/accountmap.xml
                                                            $tmpdir/icnodemap.xml
                                                            $tmpdir/trigger.xml
                                                            $tmpdir/LMLDBupdate_stat_LML.xml 
                                                            $tmpdir/step_timing_dbupdate_LML.xml 
                                                            $tmpdir/LL_jobreport_stat_LML.xml 
                                                            $tmpdir/transferreports_stat_LML.xml
                                                            $tmpdir/step_timing_jobreport_LML.xml 
                                                            "/>
  </step>

  <!-- STEP: Analyse timings of individual steps of DBupdate -->
  <step active="1" id="LMLDBupdatestat" exec_after="LMLDBupdate"  type="execute">
    <cmd  exec="$perl $instdir/LML_DBupdate/LML_analyse_DBupdate.pl -v 
                                                                    -name DBupdate 
                                                                    -infile $logdir/steps/LMLDBupdate_last.log 
                                                                    -outfile $tmpdir/LMLDBupdate_stat_LML_new.xml
                                                                    "/>
  </step>


  <!-- --------------------------------------- -->
  <!--   update DB stat info                   -->
  <!-- --------------------------------------- -->
  <!-- Getting information about all db tables -->
  <step active="1" id="LMLDBstat" exec_after="LMLDBupdate" type="execute">
    <cmd  exec="$perl $instdir/utils/exec_every_n_step_or_empty.pl $permdir/stepcount_LMLDBstat.dat 
                                                                    15 
                                                                    $instdir/utils/empty_LML.xml 
                                                                    $tmpdir/LMLDBstat.xml
                                                                    $perl $instdir/LML_DBupdate/LML_DBstat.pl -v 
                                                                                                              --dbdir=$permdir/db/
                                                                                                              --tmpdir=$tmpdir/
                                                                                                              --config $configdir/server/LLgenDB/LLgenDB.yaml
                                                                                                              --maxprocesses 6
                                                                                                              --lmlfile $tmpdir/LMLDBstat.xml
                                                                                                              "/>
  </step>

  <!-- --------------------------------------- -->
  <!--   trigger jobreport step                -->
  <!-- --------------------------------------- -->
  <step active="1" id="trigger_JobRep" exec_after="LMLDBstat" type="execute">
    <cmd exec="touch $permdir/jobreport_start.ready"/> <!-- signal to start Job Report action (next part of workflow) -->
    <cmd exec="touch $permdir/lmlstat_start.ready"/> <!-- signal to start Live View action (next part of workflow) -->
  </step>


  <!-- --------------------------------------- -->
  <!--   combine all data                      -->
  <!-- --------------------------------------- -->
  <!-- Create a single xml file with the combined data of all xml files (for archiving and replay) -->
  <step active="1" id="combineLML_all" exec_after="rawdataready" type="execute">
    <cmd  exec="$perl $instdir/LML_combiner/LML_combine_obj.pl  -noupdate
                                                                -nopstat 
                                                                -o $permdir/LMLraw_all.xml
                                                                $tmpdir/sysinfo_LML.xml 
                                                                $tmpdir/nodes_LML.xml 
                                                                $tmpdir/jobs_LML.xml
                                                                $tmpdir/reservation_LML.xml 
                                                                $tmpdir/classes_LML.xml 
                                                                $tmpdir/jobs_step_LML.xml
                                                                $tmpdir/LMLDBstat.xml 
                                                                $permdir/wservice/accountmap.xml 
                                                                $tmpdir/icnodemap.xml
                                                                "/>
  </step>

  <!-- --------------------------------------- -->
  <!--   archive LML file                      -->
  <!-- --------------------------------------- -->
  <!-- Archive the data using the unified LML created in the combineLML_all step -->
  <step active="1" id="HistoryLML_all" exec_after="combineLML_all" type="execute">
    <cmd  exec="$perl $instdir/LML_HistoryMGR/LML_da_historyMGR.pl  -infile=$permdir/LMLraw_all.xml
                                                                    -format=LML 
                                                                    -histdir=$archdir/LMLall/
                                                                    "/>
  </step>

</LML_da_workflow>
