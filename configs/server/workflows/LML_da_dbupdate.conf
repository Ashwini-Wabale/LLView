# Copyright (c) 2023 Forschungszentrum Juelich GmbH.
# This file is part of LLview. 
#
# This is an open source software distributed under the GPLv3 license. More information see the LICENSE file at the top level.
#
# Contributions must follow the Contributor License Agreement. More information see the CONTRIBUTING.md file at the top level.
#
# Contributors:
#    Wolfgang Frings (Forschungszentrum Juelich GmbH) 
#    Filipe Guimar√£es (Forschungszentrum Juelich GmbH) 

<LML_da_workflow>
  <vardefs>
    <var key="instdir"        value="${LLVIEW_HOME}/da" /> 
    <var key="configfile"     value="${LLVIEW_CONF}/server/LLgenDB/LLgenDB.yaml"/>
    <!-- Common folders -->
    <var key="tmpdir"         value="./tmp"/>
    <var key="permdir"        value="./perm"/>
    <var key="logdir"         value="./logs"/>
    <var key="archdir"        value="./arch"/>
    <var key="shareddir"      value="${LLVIEW_SHARED}/remote" />
    <!-- These variables are used by LML_da.pl -->
    <var key="signalfilename" value="RUNNING_db"/>
    <!-- These variables are used by LML_da_par_step.pl -->
    <var key="steptimingfile" value="./tmp/step_timing_dbupdate_new.xml" />
    <var key="name"           value="DBupdate" />
    <var key="stepcounter"    value="./perm/stepcounter.dat" />
    <!-- Variables used below -->
    <var key="perl"           value="perl" />
  </vardefs>

  <step active="1" id="start" exec_after="" type="execute">
    <cmd  exec="echo 'starting LML_da_dbupdate.conf'"/>
    <cmd  exec="$perl $instdir/utils/increase_counter.pl $stepcounter"/>
  </step>

  <!-- --------------------------------------- -->
  <!--   copy data produced by remote system   -->
  <!-- --------------------------------------- -->

  <step active="1" id="cpdata" exec_after="start" type="execute">
    <cmd  exec="cp -p $shareddir/sysinfo_LML.xml     $tmpdir;
                cp -p $shareddir/nodes_LML.xml       $tmpdir; 
                cp -p $shareddir/jobs_LML.xml        $tmpdir;
                cp -p $shareddir/reservation_LML.xml $tmpdir;
                cp -p $shareddir/classes_LML.xml     $tmpdir; 
                cp -p $shareddir/jobs_step_LML.xml   $tmpdir" />
  </step>

  <!-- --------------------------------------- -->
  <!--   archive old data from database        -->
  <!-- --------------------------------------- -->

  <step active="1" id="LMLDBarch" exec_after="start" type="execute">
  <cmd  exec="$perl $instdir/LML_DBupdate/LML_DBarch.pl --dbdir=$permdir/db/
                                                        --archdir=$archdir/db/
                                                        --dblist=jobstate,jobstep,loadmemstate,fsusagestate_all,fsusagestate_project,fsusagestate_scratch,fsusagestate_fastdata,fsusagestate_home,fabricstate,gpustate,sysstatstate,nodeerr,steptimings,DBstat,transfer,pcpucoresstate
                                                        --config $configfile
                                                        --maxprocesses 20
                                                        "/>
  </step>

  <!-- ---------------------------------------------------- -->
  <!--   collect data from daemons and other local sources  -->
  <!-- ---------------------------------------------------- -->

  <!--   STEP: adapter for I/O info from GPFS daemon   -->
  <step active="0" id="da_io_gpfs" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/GPFS/da_io_client_info_LML.pl 
                -lml -asc -hist -histdb=$permdir -stat  
                --prefixfile=$instdir/workflows/system/server/prefixes_mmpmon_stage2_local.txt 
                -maxwindow=9000 --nodepostfix='(i|og.jureca)$' -v  
                -tsfile $permdir/io_ts_stat.dat 
                $tmpdir/io_out_l"/>
  </step>

  <!--   STEP: adapter for infiniband info from Prometheus   -->
  <step active="0" id="da_ib" exec_after="start" type="execute">
    <cmd  exec="PAT_NODES='jrc\d\d\d\d' $perl $instdir/rms/PROMETHEUS/da_query_ib.pl -v
                                              -system JRC -lml -ascii 
                                              $tmpdir/ibms"/>
  </step>

  <!--   STEP: adapter for GPU information from gpumon daemon   -->
  <step active="0" id="da_gpus" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/SLURM/da_gpu_info_LML.pl  
                      --prefixfile=$instdir/workflows/system/server/prefixes_gpu.lst 
                      --nodepostfix='.jureca'
                      $tmpdir/gpus_LML"/>
  </step>

  <!--   STEP: copying job error information generated by Healthchecker action   -->
  <step active="0" id="da_errmsg" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/jobs_errmsg_HC_LML_new.xml   
                      $tmpdir/jobs_errmsg_HC_LML.xml   
                      $tmpdir/jobs_errmsg_HC_LML_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/jobs_errmsg_HC_LML_new.xml $tmpdir/jobs_errmsg_HC_LML_done.xml"/>
  </step>

  <!--   STEP: copying node error information generated by Healthchecker action   -->
  <step active="0" id="da_nodeerrmsg" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/nodes_errmsg_HC_LML_new.xml   
                      $tmpdir/nodes_errmsg_HC_LML.xml   
                      $tmpdir/nodes_errmsg_HC_LML_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/nodes_errmsg_HC_LML_new.xml $tmpdir/nodes_errmsg_HC_LML_done.xml"/>
  </step>

  <!--   STEP: copying interconnect mapping generated by icmap action   -->
  <step active="0" id="da_icmap" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                      $tmpdir/icnodemap_system_new.xml   
                      $tmpdir/icnodemap_system.xml
                      $tmpdir/icnodemap_system_done.xml   
                      $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/icnodemap_system_new.xml $tmpdir/icnodemap_system_done.xml"/>
  </step>

  <!--   STEP: adapter for system information from checkMK   -->
  <step active="0" id="da_checkmk" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/CheckMK/cmk_query_env.pl -v 
                      -system JRC -output $tmpdir/checkmk.xml"/>
  </step>

  <!--   STEP: adapter for power info from Prometheus   -->
  <step active="0" id="da_rackpwr" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/rms/PROMETHEUS/da_query_systat.pl -v 
                      -metric power -system JRC
                      -lml -ascii 
                      $tmpdir/rackpwr"/>
  </step>

  <!--   STEP: generating user/project/mentor/support mapping information (every 15 steps)   -->
  <step active="1" id="webservice" exec_after="start" type="execute">
  <cmd  exec="$perl $instdir/utils/exec_every_n_step_or_empty.pl $permdir/stepcount_webservice.dat 
                                                                  15
                                                                  $instdir/utils/empty_LML.xml 
                                                                  $permdir/wservice/accountmap.xml
                                                                  /usr/bin/perl $instdir/rms/JSCinternal/get_webservice_accounts.pl 
                                                                                        -system jureca 
                                                                                        --support $permdir/wservice/support_input.dat 
                                                                                        -lml $permdir/wservice/accountmap.xml
                                                                                        "/>
  </step>

  <!--   STEP: copying timing information of dbupdate action (this one)   -->
  <step active="1" id="da_step_timings_DB" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_dbupdate_new.xml   
                                                $tmpdir/step_timing_dbupdate_LML.xml   
                                                $tmpdir/step_timing_dbupdate_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_dbupdate_new.xml $tmpdir/step_timing_dbupdate_LML_done.xml"/>
  </step>

  <!--   STEP: copying timing information of part3 action   -->
  <step active="0" id="da_step_timings_P3" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_part3_new.xml   
                                                $tmpdir/step_timing_part3_LML.xml   
                                                $tmpdir/step_timing_part3_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_part3_new.xml $tmpdir/step_timing_part3_LML_done.xml"/>
  </step>

  <!--   STEP: copying timing information of jobreport action   -->
  <step active="1" id="da_step_timings_JR" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/step_timing_jobreport_new.xml   
                                                $tmpdir/step_timing_jobreport_LML.xml   
                                                $tmpdir/step_timing_jobreport_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/step_timing_jobreport_new.xml $tmpdir/step_timing_jobreport_LML_done.xml"/>
  </step>

  <!-- STEP: Copying internal statistics files -->
  <step active="1" id="da_stat" exec_after="start" type="execute">
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/LMLDBupdate_stat_LML_new.xml   
                                                $tmpdir/LMLDBupdate_stat_LML.xml   
                                                $tmpdir/LMLDBupdate_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/LMLDBupdate_stat_LML_new.xml $tmpdir/LMLDBupdate_stat_LML_done.xml"/>
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/LL_jobreport_stat_LML_new.xml   
                                                $tmpdir/LL_jobreport_stat_LML.xml   
                                                $tmpdir/LL_jobreport_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/LL_jobreport_stat_LML_new.xml $tmpdir/LL_jobreport_stat_LML_done.xml"/>
    <cmd  exec="$perl $instdir/utils/cp_if_newer_or_empty.pl  
                                                $tmpdir/transferreports_stat_LML_new.xml   
                                                $tmpdir/transferreports_stat_LML.xml   
                                                $tmpdir/transferreports_stat_LML_done.xml   
                                                $instdir/utils/empty_LML.xml"/>
    <cmd  exec="cp -p $tmpdir/transferreports_stat_LML_new.xml $tmpdir/transferreports_stat_LML_done.xml"/>
  </step>


  <!--   STEP: collection step to signal that all the data-gathering steps are completed   -->
  <step active="1" id="rawdataready" exec_after="cpdata,LMLDBarch,da_io_gpfs,da_ib,da_gpus,da_icmap,da_errmsg,da_nodeerrmsg,da_checkmk,webservice,da_rackpwr,da_step_timings_DB,da_step_timings_P3,da_step_timings_JR,da_stat" type="execute">
    <cmd  exec="echo 'raw data ready'"/>
  </step>


  <!-- --------------------------------------- -->
  <!--   add data to database                  -->
  <!-- --------------------------------------- -->
  <!-- STEP: This step should include all xml files to be included in the database -->
  <step active="1" id="LMLDBupdate" exec_after="rawdataready" type="execute">
    <cmd  exec="$perl $instdir/LML_DBupdate/LML_DBupdate.pl --dbdir=$permdir/db/
                                                            --config $configfile 
                                                            --maxprocesses 10
                                                            $tmpdir/sysinfo_LML.xml $tmpdir/nodes_LML.xml $tmpdir/jobs_LML.xml
                                                            $tmpdir/reservation_LML.xml $tmpdir/classes_LML.xml $tmpdir/jobs_step_LML.xml
                                                            $tmpdir/LMLDBstat.xml $permdir/wservice/accountmap.xml
                                                            $tmpdir/LMLDBupdate_stat_LML.xml 
                                                            $tmpdir/step_timing_dbupdate_LML.xml 
                                                            $tmpdir/LL_jobreport_stat_LML.xml 
                                                            $tmpdir/transferreports_stat_LML.xml
                                                            $tmpdir/step_timing_jobreport_LML.xml 
                                                            "/>
  </step>

  <!-- STEP: Analyse timings of individual steps of DBupdate -->
  <step active="1" id="LMLDBupdatestat" exec_after="LMLDBupdate"  type="execute">
    <cmd  exec="$perl $instdir/LML_DBupdate/LML_analyse_DBupdate.pl -v 
                                                                    -name DBupdate 
                                                                    -infile $logdir/steps/LMLDBupdate_last.log 
                                                                    -outfile $tmpdir/LMLDBupdate_stat_LML_new.xml
                                                                    "/>
  </step>


  <!-- --------------------------------------- -->
  <!--   update DB stat info                   -->
  <!-- --------------------------------------- -->
  <!-- Getting information about all db tables -->
  <step active="1" id="LMLDBstat" exec_after="LMLDBupdate" type="execute">
  <cmd  exec="$perl $instdir/utils/exec_every_n_step_or_empty.pl $permdir/stepcount_LMLDBstat.dat 
                                                                  15 
                                                                  $instdir/utils/empty_LML.xml 
                                                                  $tmpdir/LMLDBstat.xml
                                                                  $perl $instdir/LML_DBupdate/LML_DBstat.pl -v 
                                                                                                            --dbdir=$permdir/db/
                                                                                                            --tmpdir=$tmpdir/
                                                                                                            --config $configfile
                                                                                                            --maxprocesses 16
                                                                                                            --lmlfile $tmpdir/LMLDBstat.xml
                                                                                                            "/>
  </step>

  <!-- --------------------------------------- -->
  <!--   trigger jobreport step                -->
  <!-- --------------------------------------- -->
  <step active="1" id="trigger_JobRep" exec_after="LMLDBstat" type="execute">
    <cmd exec="touch $permdir/jobreport_start.ready"/> <!-- signal to start Job Report action (next part of workflow) -->
    <cmd exec="touch $permdir/lmlstat_start.ready"/> <!-- signal to start Live View action (next part of workflow) -->
  </step>


  <!-- --------------------------------------- -->
  <!--   combine all data                      -->
  <!-- --------------------------------------- -->
  <!-- Create a single xml file with the combined data of all xml files (for archiving and replay) -->
  <step active="1" id="combineLML_all" exec_after="rawdataready" type="execute">
    <cmd  exec="$perl $instdir/LML_combiner/LML_combine_obj.pl  -noupdate
                                                                -nopstat 
                                                                -o $permdir/LMLraw_all.xml
                                                                $tmpdir/sysinfo_LML.xml $tmpdir/nodes_LML.xml $tmpdir/jobs_LML.xml
                                                                $tmpdir/reservation_LML.xml $tmpdir/classes_LML.xml $tmpdir/jobs_step_LML.xml
                                                                $tmpdir/LMLDBstat.xml $permdir/wservice/accountmap.xml
                                                                "/>
  </step>

  <!-- --------------------------------------- -->
  <!--   archive LML file                      -->
  <!-- --------------------------------------- -->
  <!-- Archive the data using the unified LML created in the combineLML_all step -->
  <step active="1" id="HistoryLML_all" exec_after="combineLML_all" type="execute">
    <cmd  exec="$perl $instdir/LML_HistoryMGR/LML_da_historyMGR.pl  -infile=$permdir/LMLraw_all.xml
                                                                    -format=LML 
                                                                    -histdir=$archdir/LMLall/
                                                                    "/>
  </step>

</LML_da_workflow>